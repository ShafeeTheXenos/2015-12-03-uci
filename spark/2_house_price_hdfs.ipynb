{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: houses number of bedrooms, neighborhood, price\n",
    "\n",
    "Find the total dollar amount of properties on sale for each neighborhood\n",
    "Create a local file just on the Driver, this is not accessible by the Spark Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting houses.txt\n"
     ]
    }
   ],
   "source": [
    "%%file houses.txt\n",
    "3 Downtown 400000\n",
    "2 Downtown 240000\n",
    "3 Hilltop 650000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Downtown 400000\r\n",
      "2 Downtown 240000\r\n",
      "3 Hilltop 650000"
     ]
    }
   ],
   "source": [
    "!cat houses.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the file to the distributed file system HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/12/03 14:51:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "mkdir: `/data': File exists\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -mkdir /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/12/03 14:51:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "copyFromLocal: `/data/houses.txt': File exists\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -copyFromLocal houses.txt /data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/12/03 14:14:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Connecting to namenode via http://comet-06-55.ibnet:50070\n",
      "FSCK started by zonca (auth:SIMPLE) from /10.22.254.96 for path /data/houses.txt at Thu Dec 03 14:14:21 PST 2015\n",
      "/data/houses.txt 52 bytes, 1 block(s):  Under replicated BP-1823862164-198.202.119.184-1449177989860:blk_1073741825_1001. Target Replicas is 3 but found 1 replica(s).\n",
      "0. BP-1823862164-198.202.119.184-1449177989860:blk_1073741825_1001 len=52 repl=1 [/default-rack/10.22.254.96:50010]\n",
      "\n",
      "Status: HEALTHY\n",
      " Total size:\t52 B\n",
      " Total dirs:\t0\n",
      " Total files:\t1\n",
      " Total symlinks:\t\t0\n",
      " Total blocks (validated):\t1 (avg. block size 52 B)\n",
      " Minimally replicated blocks:\t1 (100.0 %)\n",
      " Over-replicated blocks:\t0 (0.0 %)\n",
      " Under-replicated blocks:\t1 (100.0 %)\n",
      " Mis-replicated blocks:\t\t0 (0.0 %)\n",
      " Default replication factor:\t3\n",
      " Average block replication:\t1.0\n",
      " Corrupt blocks:\t\t0\n",
      " Missing replicas:\t\t2 (66.666664 %)\n",
      " Number of data-nodes:\t\t1\n",
      " Number of racks:\t\t1\n",
      "FSCK ended at Thu Dec 03 14:14:21 PST 2015 in 5 milliseconds\n",
      "\n",
      "\n",
      "The filesystem under path '/data/houses.txt' is HEALTHY\n"
     ]
    }
   ],
   "source": [
    "!hdfs fsck /data/houses.txt -files -blocks -locations -racks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_RDD = sc.textFile(\"/data/houses.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_RDD = sc.textFile(\"file:///home/zonca/workshop/spark/houses.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/zonca/workshop/spark'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'3 Downtown 400000', u'2 Downtown 240000', u'3 Hilltop 650000']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_RDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapper: parse each line into a (key, value) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapper_parse_lines(line):\n",
    "    \"\"\"Parse line into (neighborhoood, price) pair\"\"\"\n",
    "    words = line.split()\n",
    "    return (words[1], float(words[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "house_prices_RDD = text_RDD.map(mapper_parse_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Downtown', 400000.0), (u'Downtown', 240000.0), (u'Hilltop', 650000.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_prices_RDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducer: sum values across all pairs with the same key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reducer_sum(a,b):\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Downtown', 640000.0), (u'Hilltop', 650000.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_prices_RDD.reduceByKey(reducer_sum).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise\n",
    "Copy-pasting and modifying the code above, find the **maximum** dollar amount available for each **number of bedrooms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapper_parse_lines(line):\n",
    "    \"\"\"Parse line into (number of bedrooms, price) pair\"\"\"\n",
    "    words = line.split()\n",
    "    return (int(words[0]), float(words[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_prices_RDD = text_RDD.map(mapper_parse_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 400000.0), (2, 240000.0), (3, 650000.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_prices_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reducer_max(a,b):\n",
    "    return max(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 240000.0), (3, 650000.0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_prices_RDD.reduceByKey(reducer_max).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_price_per_bedroom_RDD = house_prices_RDD.reduceByKey(reducer_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results back to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "house_prices_RDD.saveAsTextFile(\"/data/house_prices_RDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_price_per_bedroom_RDD.saveAsTextFile(\"/data/max_price_per_bedroom_RDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/12/03 14:25:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -copyToLocal /data/house_prices_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/12/03 14:28:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -copyToLocal /data/max_price_per_bedroom_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 240000.0)\r\n"
     ]
    }
   ],
   "source": [
    "!cat max_price_per_bedroom_RDD/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 650000.0)\r\n"
     ]
    }
   ],
   "source": [
    "!cat max_price_per_bedroom_RDD/part-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 400000.0)\r\n",
      "(2, 240000.0)\r\n"
     ]
    }
   ],
   "source": [
    "!cat house_prices_RDD/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 650000.0)\r\n"
     ]
    }
   ],
   "source": [
    "!cat house_prices_RDD/part-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
